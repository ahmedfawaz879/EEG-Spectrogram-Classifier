{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "ff8a12c8-4e7a-4e7d-88e3-cdf57f89bb3d",
      "cell_type": "markdown",
      "source": "EEG Seizure Detection Pipeline (CHB-MIT or TUH) - PyTorch implementation\nSingle-file end-to-end example that:\n- Loads EDF EEG files (CHB-MIT assumed) using mne\n- Windowing & label extraction (supports annotations if available)\n- Computes spectrograms (mel-spectrograms with librosa)\n- Trains a convolutional autoencoder to learn compact representations\n- Uses the encoder + a CNN classifier head to detect seizures\n\n\nRequirements:\n- Python 3.8+\n- pip install mne librosa numpy scipy matplotlib torch torchvision tqdm sklearn\n\n\nNotes:\n- Place CHB-MIT EDF files in data/chb-mit/ (subfolders allowed). If you have TUH, adapt reading.\n- If seizure annotations are present as MNE annotations they will be used. Otherwise you can provide a CSV\nwith columns: filename,start_sec,end_sec (relative to file start) and the loader will use that.\n- This script is intended as a readable, extendable starting point, not a production-ready training suite.",
      "metadata": {}
    },
    {
      "id": "59d82b6e-1e9c-4b30-b49a-7ce34da6b02e",
      "cell_type": "code",
      "source": "import os\nimport glob\nimport argparse\nfrom typing import List, Tuple, Dict\n\n\nimport numpy as np\nimport mne\nimport librosa\nfrom scipy import signal\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n\n# ----------------------------- Configuration & Utilities -----------------------------\n\n\nDEFAULT_SAMPLE_RATE = 256 # target resampling rate (Hz)\nWINDOW_SEC = 10\nWINDOW_STEP_SEC = 5\nN_MELS = 64\nHOP_LENGTH = 128\n\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n\n\ndef find_edf_files(data_dir: str) -> List[str]:\npatterns = [os.path.join(data_dir, '**', '*.edf'), os.path.join(data_dir, '**', '*.EDF')]\nfiles = []\nfor p in patterns:\nfiles.extend(glob.glob(p, recursive=True))\nfiles = sorted(list(set(files)))\nreturn files\n\n\n\n\ndef load_annotations_csv(csv_path: str) -> Dict[str, List[Tuple[float,float]]]:\n\"\"\"CSV expected: filename,start_sec,end_sec (relative seconds). Returns dict keyed by basename.\"\"\"\nann = {}\nif not os.path.exists(csv_path):\nreturn ann\nwith open(csv_path, 'r') as f:\nfor line in f:\nline = line.strip()\nif not line or line.startswith('#'):\ncontinue\nparts = line.split(',')\nif len(parts) < 3:\ncontinue\nfn = os.path.basename(parts[0])\ns = float(parts[1]); e = float(parts[2])\nann.setdefault(fn, []).append((s,e))\nreturn ann\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "82389103-6882-4c01-b778-80e0ef551305",
      "cell_type": "code",
      "source": "# ----------------------------- EDF reading, windowing, spectrograms -----------------------------\n\n\n\n\ndef read_raw_edf(path: str, picks: List[str] = None, resample_sfreq: int = DEFAULT_SAMPLE_RATE):\nraw = mne.io.read_raw_edf(path, preload=True, verbose=False)\nif picks is not None:\npicks_present = [ch for ch in picks if ch in raw.ch_names]\nif picks_present:\nraw.pick_channels(picks_present)\nif resample_sfreq is not None and raw.info['sfreq'] != resample_sfreq:\nraw.resample(resample_sfreq)\nreturn raw\n\n\n\n\ndef windows_from_raw(raw: mne.io.BaseRaw, window_sec=WINDOW_SEC, step_sec=WINDOW_STEP_SEC):\nsf = int(raw.info['sfreq'])\nwindow_samples = int(window_sec * sf)\nstep_samples = int(step_sec * sf)\ndata = raw.get_data()\nn_channels, n_samples = data.shape\nwindows = []\nstart = 0\nwhile start + window_samples <= n_samples:\nsegment = data[:, start:start+window_samples]\nt0 = start / sf\nt1 = (start + window_samples) / sf\nwindows.append((segment, t0, t1))\nstart += step_samples\nreturn windows\n\n\n\n\ndef label_window_from_annotations(t0: float, t1: float, annotations: List[Tuple[float,float]]) -> int:\n# label 1 if any overlap with annotation intervals\nfor (s,e) in annotations:\nif s < t1 and e > t0:\nreturn 1\nreturn 0\n\n\n\n\ndef compute_mel_spectrogram(segment: np.ndarray, sr: int = DEFAULT_SAMPLE_RATE, n_mels=N_MELS, hop_length=HOP_LENGTH):\n# segment shape: (n_channels, n_samples). We'll compute mel for each channel and stack as channels.\nspecs = []\nfor ch in segment:\n# librosa expects float32\nch = ch.astype(np.float32)\nS = librosa.feature.melspectrogram(y=ch, sr=sr, n_mels=n_mels, hop_length=hop_length)\nS_db = librosa.power_to_db(S, ref=np.max)\nspecs.append(S_db)\n# stack -> (n_channels, n_mels, time_frames)\nspec = np.stack(specs, axis=0)\nreturn spec\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2aa92253-4377-4e1d-969a-ea1939a1ec4a",
      "cell_type": "code",
      "source": "# ----------------------------- Dataset -----------------------------\n\n\nclass EEGSpectrogramDataset(Dataset):\ndef __init__(self, records: List[Tuple[str, int, int, np.ndarray]]):\n\"\"\"records: list of tuples (basename, label, idx, spec_array)\nspec_array: np.ndarray (channels, n_mels, t)\n\"\"\"\nself.records = records\n\n\ndef __len__(self):\nreturn len(self.records)\n\n\ndef __getitem__(self, idx):\nfn, label, widx, spec = self.records[idx]\n# normalize per-example\nspec = (spec - spec.mean()) / (spec.std() + 1e-8)\n# convert to float32\nspec = spec.astype(np.float32)\n# if single channel, expand\n# Torch conv2d expects (C,H,W) so our spec already in (channels, n_mels, t)\nx = torch.from_numpy(spec)\ny = torch.tensor(label, dtype=torch.long)\nreturn x, y\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fac50deb-8b4c-41f7-9f61-137b3729117e",
      "cell_type": "code",
      "source": "# ----------------------------- Models -----------------------------\n\n\nclass ConvAutoencoder(nn.Module):\ndef __init__(self, in_ch=1, embedding_dim=128):\nsuper().__init__()\n# Encoder\nself.encoder = nn.Sequential(\nnn.Conv2d(in_ch, 16, kernel_size=3, stride=2, padding=1),\nnn.ReLU(True),\nnn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\nnn.ReLU(True),\nnn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\nnn.ReLU(True),\nnn.Flatten(),\n)\n# dummy forward to compute conv output size\nself._embedding_dim = embedding_dim\nself.fc_enc = nn.Linear(64 * 8 * 8, embedding_dim) # assumes input dims (in_ch, 64, 64) roughly\n\n\n# Decoder\nself.fc_dec = nn.Linear(embedding_dim, 64 * 8 * 8)\nself.decoder = nn.Sequential(\nnn.Unflatten(1, (64, 8, 8)),\nnn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\nnn.ReLU(True),\nnn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\nnn.ReLU(True),\nnn.ConvTranspose2d(16, in_ch, kernel_size=4, stride=2, padding=1),\n)\n\n\ndef forward(self, x):\nz = self.encoder(x)\nz = self.fc_enc(z)\nout = self.fc_dec(z)\nout = self.decoder(out)\nreturn out, z\n\n\n\n\nclass ClassifierHead(nn.Module):\ndef __init__(self, encoder: nn.Module, embedding_dim=128, n_classes=2):\nsuper().__init__()\nself.encoder = encoder\n# freeze encoder layers if desired outside\nself.fc = nn.Sequential(\nnn.Linear(embedding_dim, 64),\nnn.ReLU(True),\nnn.Dropout(0.4),\nnn.Linear(64, n_classes)\n)\n\n\ndef forward(self, x):\n# x shape: (B, C, H, W)\nz = self.encoder(x)\nz = self.fc(z)\nreturn z\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2b2955f1-76d3-4aff-ada5-c5c331d314be",
      "cell_type": "code",
      "source": "# ----------------------------- Training loops -----------------------------\nz = self.fc_enc(z)\nreturn z\n\n\nenc_wrap = EncoderWrapper(encoder_model).to(DEVICE)\nclf = ClassifierHead(enc_wrap, embedding_dim=encoder_model._embedding_dim, n_classes=2).to(DEVICE)\n\n\n# optionally freeze encoder\nfor p in enc_wrap.encoder.parameters():\np.requires_grad = False\nfor p in enc_wrap.fc_enc.parameters():\np.requires_grad = True\n\n\ncriterion = nn.CrossEntropyLoss()\nopt = optim.Adam(filter(lambda p: p.requires_grad, clf.parameters()), lr=lr)\n\n\nfor epoch in range(epochs):\nclf.train()\npbar = tqdm(train_loader, desc=f'CLF Epoch {epoch+1}/{epochs}')\nfor x,y in pbar:\nx = x.to(DEVICE)\nx = nn.functional.interpolate(x, size=(64,64), mode='bilinear', align_corners=False)\ny = y.to(DEVICE)\nlogits = clf(x)\nloss = criterion(logits, y)\nopt.zero_grad()\nloss.backward()\nopt.step()\npbar.set_postfix(loss=loss.item())\n\n\n# validation\nclf.eval()\nys, ypreds, yprob = [], [], []\nwith torch.no_grad():\nfor x,y in val_loader:\nx = x.to(DEVICE)\nx = nn.functional.interpolate(x, size=(64,64), mode='bilinear', align_corners=False)\ny = y.to(DEVICE)\nlogits = clf(x)\nprobs = torch.softmax(logits, dim=1)[:,1].cpu().numpy()\npreds = logits.argmax(dim=1).cpu().numpy()\nys.extend(y.cpu().numpy().tolist())\nypreds.extend(preds.tolist())\nyprob.extend(probs.tolist())\ntry:\nauc = roc_auc_score(ys, yprob)\nexcept Exception:\nauc = None\nprint('\\nValidation AUC:', auc)\nprint(classification_report(ys, ypreds))\nif out_path:\ntorch.save(clf.state_dict(), out_path)\nreturn clf\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b75821be-7bf7-4c8f-b3dc-ecd1a98ea402",
      "cell_type": "code",
      "source": "# ----------------------------- Full pipeline orchestration -----------------------------\n\n\n\n\ndef build_records_from_edf(files: List[str], ann_csv: str = None, picks: List[str] = None, max_files=None):\nann_map = load_annotations_csv(ann_csv) if ann_csv else {}\nrecords = []\nfor i, path in enumerate(files):\nif max_files and i >= max_files:\nbreak\nbasename = os.path.basename(path)\nprint('Reading', basename)\ntry:\nraw = read_raw_edf(path, picks=picks, resample_sfreq=DEFAULT_SAMPLE_RATE)\nexcept Exception as e:\nprint('Failed to read', path, e)\ncontinue\nwindows = windows_from_raw(raw)\nanns = ann_map.get(basename, [])\n# if MNE annotations available, convert\nif hasattr(raw, 'annotations') and raw.annotations is not None and len(raw.annotations) > 0:\nanns = [(ann['onset'], ann['onset']+ann['duration']) for ann in raw.annotations]\n\n\nfor widx, (segment, t0, t1) in enumerate(windows):\nlabel = label_window_from_annotations(t0, t1, anns) if anns else 0\nspec = compute_mel_spectrogram(segment, sr=DEFAULT_SAMPLE_RATE)\n# optionally reduce channels to 1 by averaging\n# here we keep all channels as separate channels\nrecords.append((basename, label, widx, spec))\nreturn records\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "11cf5377-a6bd-4d13-928b-9ad1e13fd1e1",
      "cell_type": "code",
      "source": "# ----------------------------- Example entrypoint -----------------------------\n\n\n\n\ndef main(args):\nfiles = find_edf_files(args.data_dir)\nif len(files) == 0:\nraise RuntimeError('No EDF files found in ' + args.data_dir)\nprint(f'Found {len(files)} EDF files')\n\n\nrecords = build_records_from_edf(files, ann_csv=args.ann_csv, picks=None, max_files=args.max_files)\nprint(f'Built {len(records)} windows')\n\n\n# Split dataset\ntrain_recs, test_recs = train_test_split(records, test_size=0.2, random_state=42, stratify=[r[1] for r in records])\ntrain_recs, val_recs = train_test_split(train_recs, test_size=0.2, random_state=42, stratify=[r[1] for r in train_recs])\n\n\ntrain_ds = EEGSpectrogramDataset(train_recs)\nval_ds = EEGSpectrogramDataset(val_recs)\ntest_ds = EEGSpectrogramDataset(test_recs)\n\n\ntrain_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_ds, batch_size=args.batch_size, shuffle=False, num_workers=2)\n\n\n# Autoencoder pretraining on entire training set\nin_ch = train_recs[0][3].shape[0]\nae = ConvAutoencoder(in_ch=in_ch, embedding_dim=128)\nprint('Training autoencoder...')\nae = train_autoencoder(ae, train_loader, epochs=args.ae_epochs, lr=args.ae_lr, out_path=args.ae_out)\n\n\n# Classifier training\nprint('Training classifier...')\nclf = train_classifier(ae, train_loader, val_loader, epochs=args.clf_epochs, lr=args.clf_lr, out_path=args.clf_out)\n\n\n# Evaluate on test set\nclf.eval()\nys, ypreds, yprob = [], [], []\nwith torch.no_grad():\nfor x,y in test_loader:\nx = x.to(DEVICE)\nx = nn.functional.interpolate(x, size=(64,64), mode='bilinear', align_corners=False)\nlogits = clf(x)\nprobs = torch.softmax(logits, dim=1)[:,1].cpu().numpy()\npreds = logits.argmax(dim=1).cpu().numpy()\nys.extend(y.numpy().tolist())\nypreds.extend(preds.tolist())\nyprob.extend(probs.tolist())\nprint('\\nTest results:')\ntry:\nauc = roc_auc_score(ys, yprob)\nexcept Exception:\nauc = None\nprint('AUC:', auc)\nprint(classification_report(ys, ypreds))\n\n\n\n\nif __name__ == '__main__':\nparser = argparse.ArgumentParser()\nparser.add_argument('--data_dir', type=str, default='data/chb-mit')\nparser.add_argument('--ann_csv', type=str, default='')\nparser.add_argument('--out_dir', type=str, default='runs')\nparser.add_argument('--max_files', type=int, default=None)\nparser.add_argument('--batch_size', type=int, default=16)\nparser.add_argument('--ae_epochs', type=int, default=10)\nparser.add_argument('--clf_epochs', type=int, default=20)\nparser.add_argument('--ae_lr', type=float, default=1e-3)\nparser.add_argument('--clf_lr', type=float, default=1e-4)\nparser.add_argument('--ae_out', type=str, default='ae.pth')\nparser.add_argument('--clf_out', type=str, default='clf.pth')\nargs = parser.parse_args()\nos.makedirs(args.out_dir, exist_ok=True)\nargs.ae_out = os.path.join(args.out_dir, args.ae_out)\nargs.clf_out = os.path.join(args.out_dir, args.clf_out)\nmain(args)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}